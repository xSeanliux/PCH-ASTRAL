{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0af6b8ed",
   "metadata": {},
   "source": [
    "For each character calculate:\n",
    "- Polymorphism: average load, average number of languages per state, number of languages with a polymorphism\n",
    "- Number of states: num states, num informative states\n",
    "- Homoplasy: num homoplastic states, num informative homoplastic states, number of languages exhibiting a homoplastic state [note: canâ€™t do for IE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52f5159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_FACTOR = [0.8]\n",
    "H_FACTOR = [\"0.1\"]\n",
    "C_FACTOR = [0.25, 0.5, 1,3, ]\n",
    "POLYMORPHISM = [\"no\", \"low\", \"high\"]\n",
    "\n",
    "TREES = 16\n",
    "REPLICAS = 4\n",
    "\n",
    "OUTPUT_FOLDER = 'simulated_data_theorypaper'\n",
    "\n",
    "N_HP_STATES = 1\n",
    "HP_STATES = [\n",
    "    str(i) for i in range(N_HP_STATES)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58ab6e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdb120b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistics(row):\n",
    "    # row is a dict of language -> list of states\n",
    "\n",
    "    # polymorphism statistics \n",
    "\n",
    "    # average load defined as the avg. number of states per language\n",
    "    avg_load = np.array([ len(v) for _, v in row.items() ]).mean()\n",
    "    # ratio of langs with a polymorphism\n",
    "    langs_with_poly = len([ k for k, v in row.items() if len(v) > 1 ])\n",
    "    ratio_langs_with_poly = langs_with_poly / len(row)\n",
    "    # avg. no. of languages per state\n",
    "    state_lang_count = Counter() # counter of state -> how many languages have that state\n",
    "    for k, v in row.items():\n",
    "        for s in v:\n",
    "            state_lang_count[s] += 1\n",
    "    avg_langs_per_state = np.array(list(state_lang_count.values())).mean()\n",
    "\n",
    "    # State statistics\n",
    "    num_states = len(state_lang_count)\n",
    "    num_informative_states = len([ k for k, v in state_lang_count.items() if v > 1 ]) # number of states with more than one character\n",
    "\n",
    "    # num homoplastic states \n",
    "    hp_state_count = Counter({\n",
    "        k: state_lang_count[k] for k in HP_STATES\n",
    "        if k in state_lang_count \n",
    "    })\n",
    "    n_hp_states = len(hp_state_count)\n",
    "    # average size of homoplastic states\n",
    "    avg_hp_size = sum(hp_state_count.values()) / len(hp_state_count) if len(hp_state_count) > 0 else None\n",
    "\n",
    "\n",
    "    return (\n",
    "        avg_load, \n",
    "        ratio_langs_with_poly, \n",
    "        avg_langs_per_state,\n",
    "        num_states, \n",
    "        num_informative_states,\n",
    "        n_hp_states,\n",
    "        avg_hp_size\n",
    "    )\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1806ad33",
   "metadata": {},
   "source": [
    "Quartet statistics: \n",
    "- EVANS-ONE-K: get number of distinct quartets / n^4\n",
    "- EVANS-ALL-K: get number of ties "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98011da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.abspath('../lib'))\n",
    "from getQuartets import get_new_omp\n",
    "import scipy.special\n",
    "\n",
    "def get_quartet_statistics(\n",
    "    csv_path: str\n",
    "):\n",
    "    # all information is calculated with NO information of the HP state\n",
    "    N = len(pd.read_csv(csv_path).drop(columns= ['id', 'feature', 'weight']).columns)\n",
    "    (md, evans_one_res) = get_new_omp(\n",
    "        csv_path = csv_path,\n",
    "        mode = 12,\n",
    "    ) \n",
    "    evans_all_res, ties, unique_best = md['votes'], md['ties'], md['unique_best']\n",
    "    evans_all_covered_tuples = set([\n",
    "        tuple(sorted(t))\n",
    "        for t in evans_all_res.keys()\n",
    "    ])\n",
    "\n",
    "    n_c_4 = scipy.special.comb(N, 4, exact=True)\n",
    "    ratio_distinct_evans_one = len(evans_one_res) / n_c_4\n",
    "    ratio_distinct_evans_all = len(evans_all_res) / n_c_4\n",
    "    ratio_covered_tuples_evans_all = len(evans_all_covered_tuples) / n_c_4\n",
    "    assert (2 * ties + unique_best) == len(evans_one_res)\n",
    "    ratio_evans_one_ties = ties / (len(evans_one_res))\n",
    "    return ratio_distinct_evans_one, ratio_distinct_evans_all, ratio_evans_one_ties, ratio_covered_tuples_evans_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3b46eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd \n",
    "OMP = Path(os.getenv(\"TALLIS\")) / \"OneMostProb\"\n",
    "\n",
    "def get_single_dataset_stats(\n",
    "    csv_path: str,\n",
    "):\n",
    "    dataset = pd.read_csv(csv_path).drop(columns= ['id', 'feature', 'weight'])\n",
    "\n",
    "    dataset.head()\n",
    "\n",
    "    row_stats = []\n",
    "\n",
    "    for i, row in dataset.iterrows():\n",
    "        row = row.to_dict()\n",
    "        row = {\n",
    "            k: str(v).split('/') for k, v in row.items()\n",
    "        }\n",
    "        row_stats.append(get_statistics(row))\n",
    "\n",
    "    \n",
    "\n",
    "    dataset_stats = pd.DataFrame.from_records(\n",
    "        data = row_stats,\n",
    "        columns = [\n",
    "            \"avg_load\",\n",
    "            \"ratio_langs_with_poly\",\n",
    "            \"avg_langs_per_state\",\n",
    "            \"num_states\",\n",
    "            \"num_informative_states\",\n",
    "            \"num_hp_states\",\n",
    "            \"avg_hp_size\",\n",
    "        ]\n",
    "    ).mean(axis=0)\n",
    "    ratio_distinct_evans_one, ratio_distinct_evans_all, ratio_evans_one_ties, ratio_covered_tuples_evans_all= get_quartet_statistics(csv_path)\n",
    "    dataset_stats['ratio_distinct_evans_one'] = ratio_distinct_evans_one\n",
    "    dataset_stats['ratio_distinct_evans_all'] = ratio_distinct_evans_all\n",
    "    dataset_stats['ratio_evans_one_ties'] = ratio_evans_one_ties\n",
    "    dataset_stats['ratio_covered_tuples_evans_all'] = ratio_covered_tuples_evans_all\n",
    "    return dataset_stats.to_frame().T\n",
    "\n",
    "def get_single_sim_dataset_stats(\n",
    "    poly: str,\n",
    "    hf: float,\n",
    "    ef: int,\n",
    "    cf: int,\n",
    "    tree: int,\n",
    "    rep: int,\n",
    "):\n",
    "    csv_path = OMP / \"example\" / OUTPUT_FOLDER / f\"{poly}_{hf}_{ef}_{cf}\" / f\"sim_tree{tree}_{rep}.csv\"\n",
    "    return get_single_dataset_stats(csv_path)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4757a9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3bd552",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:06,  1.14s/it]"
     ]
    }
   ],
   "source": [
    "different_conditions_data = []\n",
    "for (ef, hf, cf, poly) in tqdm(product(E_FACTOR, H_FACTOR, C_FACTOR, POLYMORPHISM)):\n",
    "    for tree in range(1, 9):\n",
    "        dataset_stats = get_single_sim_dataset_stats(\n",
    "            poly = poly,\n",
    "            ef = ef,\n",
    "            hf = hf,\n",
    "            cf = cf,\n",
    "            tree = tree,\n",
    "            rep = 1,\n",
    "        )\n",
    "        dataset_stats[\"poly\"] = poly\n",
    "        dataset_stats[\"ef\"] = ef\n",
    "        dataset_stats[\"hf\"] = hf\n",
    "        dataset_stats[\"cf\"] = cf\n",
    "        different_conditions_data.append(dataset_stats)\n",
    "    #     if tree > 2:\n",
    "    #         break\n",
    "    # break\n",
    "    # means = condition_data.mean(axis=0)\n",
    "\n",
    "# print(different_conditions_data)\n",
    "different_conditions_data = pd.concat(different_conditions_data, ignore_index=True)\n",
    "# print(different_conditions_data.head())\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2cc42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_load</th>\n",
       "      <th>ratio_langs_with_poly</th>\n",
       "      <th>avg_langs_per_state</th>\n",
       "      <th>num_states</th>\n",
       "      <th>num_informative_states</th>\n",
       "      <th>num_hp_states</th>\n",
       "      <th>avg_hp_size</th>\n",
       "      <th>ratio_distinct_evans_one</th>\n",
       "      <th>ratio_distinct_evans_all</th>\n",
       "      <th>ratio_evans_one_ties</th>\n",
       "      <th>ratio_covered_tuples_evans_all</th>\n",
       "      <th>poly</th>\n",
       "      <th>ef</th>\n",
       "      <th>hf</th>\n",
       "      <th>cf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.040833</td>\n",
       "      <td>0.037917</td>\n",
       "      <td>3.000281</td>\n",
       "      <td>12.368750</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>0.096875</td>\n",
       "      <td>3.451613</td>\n",
       "      <td>0.968801</td>\n",
       "      <td>1.005546</td>\n",
       "      <td>0.006704</td>\n",
       "      <td>0.962379</td>\n",
       "      <td>mod</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.038958</td>\n",
       "      <td>0.036146</td>\n",
       "      <td>3.350280</td>\n",
       "      <td>11.578125</td>\n",
       "      <td>4.518750</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>5.214286</td>\n",
       "      <td>0.983470</td>\n",
       "      <td>1.040321</td>\n",
       "      <td>0.010797</td>\n",
       "      <td>0.972852</td>\n",
       "      <td>mod</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.036250</td>\n",
       "      <td>0.033542</td>\n",
       "      <td>2.794377</td>\n",
       "      <td>13.190625</td>\n",
       "      <td>4.909375</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.960226</td>\n",
       "      <td>1.012844</td>\n",
       "      <td>0.003724</td>\n",
       "      <td>0.956650</td>\n",
       "      <td>mod</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.041042</td>\n",
       "      <td>0.036771</td>\n",
       "      <td>3.013845</td>\n",
       "      <td>12.312500</td>\n",
       "      <td>4.315625</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.933881</td>\n",
       "      <td>0.972487</td>\n",
       "      <td>0.009417</td>\n",
       "      <td>0.925634</td>\n",
       "      <td>mod</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.042396</td>\n",
       "      <td>0.038229</td>\n",
       "      <td>3.314765</td>\n",
       "      <td>11.484375</td>\n",
       "      <td>3.503125</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>0.948586</td>\n",
       "      <td>1.029922</td>\n",
       "      <td>0.022003</td>\n",
       "      <td>0.928334</td>\n",
       "      <td>mod</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_load  ratio_langs_with_poly  avg_langs_per_state  num_states  \\\n",
       "0  1.040833               0.037917             3.000281   12.368750   \n",
       "1  1.038958               0.036146             3.350280   11.578125   \n",
       "2  1.036250               0.033542             2.794377   13.190625   \n",
       "3  1.041042               0.036771             3.013845   12.312500   \n",
       "4  1.042396               0.038229             3.314765   11.484375   \n",
       "\n",
       "   num_informative_states  num_hp_states  avg_hp_size  \\\n",
       "0                4.800000       0.096875     3.451613   \n",
       "1                4.518750       0.087500     5.214286   \n",
       "2                4.909375       0.093750     3.500000   \n",
       "3                4.315625       0.093750     3.800000   \n",
       "4                3.503125       0.093750     5.400000   \n",
       "\n",
       "   ratio_distinct_evans_one  ratio_distinct_evans_all  ratio_evans_one_ties  \\\n",
       "0                  0.968801                  1.005546              0.006704   \n",
       "1                  0.983470                  1.040321              0.010797   \n",
       "2                  0.960226                  1.012844              0.003724   \n",
       "3                  0.933881                  0.972487              0.009417   \n",
       "4                  0.948586                  1.029922              0.022003   \n",
       "\n",
       "   ratio_covered_tuples_evans_all poly   ef   hf  cf  \n",
       "0                        0.962379  mod  0.8  0.1   1  \n",
       "1                        0.972852  mod  0.8  0.1   1  \n",
       "2                        0.956650  mod  0.8  0.1   1  \n",
       "3                        0.925634  mod  0.8  0.1   1  \n",
       "4                        0.928334  mod  0.8  0.1   1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "different_conditions_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bbbc1a",
   "metadata": {},
   "source": [
    "RT-Screened-1 Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5cddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_screened_1_stats = get_single_dataset_stats(OMP / \"example\" / \"rt_2025_poly\" / \"rt_2025_poly_screened_lv_1.csv\").mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb6bf25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0798266461624493"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt_screened_1_stats['avg_load']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41b84b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGETS = [\n",
    "    \"avg_load\",\n",
    "    \"ratio_langs_with_poly\",\n",
    "    \"avg_langs_per_state\",\n",
    "    \"num_states\",\n",
    "    \"num_informative_states\",\n",
    "    \"ratio_distinct_evans_one\",\n",
    "    \"ratio_distinct_evans_all\",\n",
    "    \"ratio_evans_one_ties\",\n",
    "    \"num_hp_states\",\n",
    "    \"avg_hp_size\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9900d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa7696c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_by_chr_and_hp(\n",
    "    chrf,\n",
    "    tgt, \n",
    "    tgt_name,\n",
    "    draw_ie_ref = True,\n",
    "):\n",
    "    fg = sns.catplot(\n",
    "        data = different_conditions_data[(different_conditions_data['cf'] == chrf)],\n",
    "        col = 'ef',\n",
    "        x = 'poly',\n",
    "        y = tgt,\n",
    "        hue = 'hf',\n",
    "        kind = \"point\",\n",
    "        aspect=0.5,\n",
    "    )\n",
    "    if draw_ie_ref:\n",
    "        fg.refline(y = rt_screened_1_stats[tgt])\n",
    "    fg.set_titles(\n",
    "        col_template=\"Evo. Factor = {col_name}\",\n",
    "    )\n",
    "    # fg.set_ylabels(tgt_name)\n",
    "    fg.set_xlabels(\"Polymorphism\")\n",
    "    fg.set_xticklabels(rotation=60)\n",
    "    fg.figure.subplots_adjust(top=0.8)\n",
    "    fg.figure.suptitle(f\"1 homoplastic state: {tgt_name} on {chrf * 320} characters\", wrap=True)\n",
    "    # fg.tight_layout()\n",
    "    fg.figure.savefig(OMP / \"figs\" / f\"stat-{tgt}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7a60d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_by_chr_and_hp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plot_by_chr_and_hp(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_load\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage Polymorphism Load\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m plot_by_chr_and_hp(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mratio_langs_with_poly\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRatio of languages with a polymorphic state\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m plot_by_chr_and_hp(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_langs_per_state\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage languages per state\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_by_chr_and_hp' is not defined"
     ]
    }
   ],
   "source": [
    "plot_by_chr_and_hp(1, \"avg_load\", 'Average Polymorphism Load')\n",
    "plot_by_chr_and_hp(1, \"ratio_langs_with_poly\", 'Ratio of languages with a polymorphic state')\n",
    "plot_by_chr_and_hp(1, \"avg_langs_per_state\", 'Average languages per state')\n",
    "plot_by_chr_and_hp(1, \"num_states\", 'Average number of states')\n",
    "plot_by_chr_and_hp(1, \"num_informative_states\", 'Average number of informative (big) states')\n",
    "plot_by_chr_and_hp(1, \"ratio_distinct_evans_one\", 'Average number of distinct informative quartets in EVANS-ONE / nC4')\n",
    "plot_by_chr_and_hp(1, \"ratio_distinct_evans_all\", 'Average number of distinct informative quartets in EVANS-ALL / nC4')\n",
    "plot_by_chr_and_hp(1, \"ratio_covered_tuples_evans_all\", 'Ratio of four languages (nC4 in total) that have at least one quartet as generated by EVANS-ALL')\n",
    "plot_by_chr_and_hp(1, \"ratio_evans_one_ties\", 'No. of times that two topologies appear for the same set of four taxa / number of quartets generated under EVANS-ONE')\n",
    "plot_by_chr_and_hp(1, \"num_hp_states\", 'Avg. Number of homoplastic states that appear.', draw_ie_ref=False)\n",
    "plot_by_chr_and_hp(1, \"avg_hp_size\", 'Average homoplastic state size', draw_ie_ref= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269d0026",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phylo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
